AWSTemplateFormatVersion: '2010-09-09'
Description: |
  Data pipeline that copies DynamoDB source table to DynamoDB destination table using S3 bucket as a temporal storage

Parameters:
  SourceTableName:
    Type: String
    Description: Source DynamoDB table name

  DestinationTableName:
    Type: String
    Description: Destination DynamoDB table name

  ReadThroughputRatio:
    Type: String
    Description: Read DynamoDB ratio. Enter value between 0.1-1.0. 1.0 == 100%, 0.1 == 10%
    Default: "1.0"

  WriteThroughputRatio:
    Type: String
    Description: Write DynamoDB ratio. Enter value between 0.1-1.0. 1.0 == 100%, 0.1 == 10%
    Default: "1.0"

  ActivateDataPipeline:
    AllowedValues:
    - "true"
    - "false"
    Type: String
    Description: Activate Data Pipeline
    Default: "true"

Resources:
  TempS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete

  LogsS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete

  DynamoDBToDynamoDB:
    Type: AWS::DataPipeline::Pipeline
    Properties:
      Name: "dynamo-db-to-dynamo-db"
      Description: "Pipeline to backup DynamoDB data to S3"
      Activate: true
      ParameterObjects:

      - Id: "myDDBReadThroughputRatio"
        Attributes:
        - Key: "description"
          StringValue: "DynamoDB read throughput ratio"
        - Key: "type"
          StringValue: "Double"
        - Key: "default"
          StringValue: !Ref ReadThroughputRatio
        - Key: "watermark"
          StringValue: "Enter value between 0.1-1.0"

      - Id: "myDDBWriteThroughputRatio"
        Attributes:
        - Key: "description"
          StringValue: "DynamoDB write throughput ratio"
        - Key: "type"
          StringValue: "Double"
        - Key: "default"
          StringValue: !Ref WriteThroughputRatio
        - Key: "watermark"
          StringValue: "Enter value between 0.1-1.0"

      - Id: "myDDBRegion"
        Attributes:
        - Key: "description"
          StringValue: "Region of the DynamoDB table"
        - Key: "type"
          StringValue: "String"
        - Key: "default"
          StringValue: "eu-west-1"
        - Key: "watermark"
          StringValue: "eu-west-1"

      - Id: "myTempS3"
        Attributes:
        - Key: "description"
          StringValue: "S3 temp bucket"
        - Key: "type"
          StringValue: "AWS::S3::ObjectKey"
        - Key: "default"
          StringValue: !Sub "s3://${TempS3Bucket}"

      - Id: "myLogsS3"
        Attributes:
        - Key: "description"
          StringValue: "S3 logs bucket"
        - Key: "type"
          StringValue: "AWS::S3::ObjectKey"
        - Key: "default"
          StringValue: !Sub "s3://${LogsS3Bucket}"

      - Id: "myDDBSourceTableName"
        Attributes:
        - Key: "description"
          StringValue: "Source DynamoDB table name"
        - Key: "type"
          StringValue: "String"
        - Key: "default"
          StringValue: !Ref SourceTableName

      - Id: "myDDBDestinationTableName"
        Attributes:
        - Key: "description"
          StringValue: "Destination DynamoDB table name"
        - Key: "type"
          StringValue: "String"
        - Key: "default"
          StringValue: !Ref DestinationTableName

      PipelineObjects:

      - Id: "Default"
        Name: "Default"
        Fields:
        - Key: "type"
          StringValue: "Default"
        - Key: "scheduleType"
          StringValue: "ondemand"
        - Key: "failureAndRerunMode"
          StringValue: "CASCADE"
        - Key: "role"
          StringValue: "DataPipelineDefaultRole"
        - Key: "resourceRole"
          StringValue: "DataPipelineDefaultResourceRole"
        - Key: "pipelineLogUri"
          StringValue: "#{myLogsS3}"

      - Id: "DDBSourceTable"
        Name: "DDBSourceTable"
        Fields:
        - Key: "tableName"
          StringValue: "#{myDDBSourceTableName}"
        - Key: "type"
          StringValue: "DynamoDBDataNode"
        - Key: "readThroughputPercent"
          StringValue: "#{myDDBReadThroughputRatio}"

      - Id: "S3TempLocation"
        Name: "Temp s3 location"
        Fields:
        - Key: "type"
          StringValue: "S3DataNode"
        - Key: "directoryPath"
          StringValue: "#{myTempS3}/#{format(@scheduledStartTime, 'YYYY-MM-dd-HH-mm-ss')}"

      - Id: "DDBDestinationTable"
        Name: "DDBDestinationTable"
        Fields:
        - Key: "tableName"
          StringValue: "#{myDDBDestinationTableName}"
        - Key: "type"
          StringValue: "DynamoDBDataNode"
        - Key: "writeThroughputPercent"
          StringValue: "#{myDDBWriteThroughputRatio}"

      - Id: "NameEmrCluster"
        Name: "NameEmrCluster"
        Fields:
        - Key: "terminateAfter"
          StringValue: "5 Hours"
        - Key: "amiVersion"
          StringValue: "3.8.0"
        - Key: "masterInstanceType"
          StringValue: "m3.xlarge"
        - Key: "coreInstanceType"
          StringValue: "m3.xlarge"
        - Key: "coreInstanceCount"
          StringValue: "2"
        - Key: "type"
          StringValue: "EmrCluster"

      - Id: "TableBackupActivity"
        Name: "TableBackupActivity"
        Fields:
        - Key: "runsOn"
          RefValue: "NameEmrCluster"
        - Key: "resizeClusterBeforeRunning"
          StringValue: "true"
        - Key: "type"
          StringValue: "EmrActivity"
        - Key: "input"
          RefValue: "DDBSourceTable"
        - Key: "output"
          RefValue: "S3TempLocation"
        - Key: "step"
          StringValue: "s3://dynamodb-emr-#{myDDBRegion}/emr-ddb-storage-handler/2.1.0/emr-ddb-2.1.0.jar,org.apache.hadoop.dynamodb.tools.DynamoDbExport,#{output.directoryPath},#{input.tableName},#{input.readThroughputPercent}"

      - Id: "TableLoadActivity"
        Name: "TableLoadActivity"
        Fields:
        - Key: "dependsOn"
          RefValue: "TableBackupActivity"
        - Key: "runsOn"
          RefValue: "NameEmrCluster"
        - Key: "resizeClusterBeforeRunning"
          StringValue: "true"
        - Key: "type"
          StringValue: "EmrActivity"
        - Key: "input"
          RefValue: "S3TempLocation"
        - Key: "output"
          RefValue: "DDBDestinationTable"
        - Key: "step"
          StringValue: "s3://dynamodb-emr-#{myDDBRegion}/emr-ddb-storage-handler/2.1.0/emr-ddb-2.1.0.jar,org.apache.hadoop.dynamodb.tools.DynamoDbImport,#{input.directoryPath},#{output.tableName},#{output.writeThroughputPercent}"

      - Id: "S3CleanupActivity"
        Name: "S3CleanupActivity"
        Fields:
        - Key: "dependsOn"
          RefValue: "TableLoadActivity"
        - Key: "runsOn"
          RefValue: "NameEmrCluster"
        - Key: "type"
          StringValue: "ShellCommandActivity"
        - Key: "input"
          RefValue: "S3TempLocation"
        - Key: "command"
          StringValue: "(sudo yum -y update aws-cli) && (aws s3 rm #{input.directoryPath} --recursive)"

Outputs:
  TempS3Bucket:
    Value: !Ref TempS3Bucket
    Description: Name of temp S3 bucket
  LogsS3Bucket:
    Value: !Ref LogsS3Bucket
    Description: Name of log S3 bucket
  DynamoDBToDynamoDBDataPipeline:
    Value: !Ref DynamoDBToDynamoDB
    Description: Pipeline ID